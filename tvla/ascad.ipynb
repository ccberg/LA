{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Classical LA methods applied to the ASCAD database\n",
    "###### This includes my implementations of $\\chi^2$ and Welch's t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "from settings.ascad import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "['Attack_traces', 'Profiling_traces']"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "ascad_hdf = h5py.File(f\"{ASCAD_DATA}{ASCAD_DATA_VAR}/{ASCADDataType.default}.h5\", 'r')\n",
    "\n",
    "keys = list(ascad_hdf.keys())\n",
    "keys"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "['labels', 'metadata', 'traces']"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_group = ascad_hdf[\"Attack_traces\"]\n",
    "\n",
    "att_keys = list(att_group.keys())\n",
    "att_keys"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "(100000, 1400)"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_traces = att_group[\"traces\"]\n",
    "\n",
    "att_traces.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "(100000,)"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_labels = att_group[\"labels\"]\n",
    "\n",
    "att_labels.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 31562.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "for _ in tqdm.tqdm(att_traces[1:10]):\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "att_head = att_traces[1:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ./welch_t_test.ipynb\n",
      "(0.0, 598.0, 1.0) (0.0, 99, nan)\n",
      "(0.0, 300.119807070072, 1.0) (-443.95712826391065, 99, nan)\n",
      "False True\n"
     ]
    }
   ],
   "source": [
    "from settings.nbloader import NotebookLoader\n",
    "\n",
    "nb = NotebookLoader(\"../\").load_module(\"tvla.welch_t_test\")\n",
    "tp = nb.TraceProcessor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "(385,)"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "fixed_1_ix = np.where(np.array(att_labels) == 1)[0]\n",
    "fixed_2_ix = np.where(np.array(att_labels) == 2)[0]\n",
    "random_not_1_ix = np.array(np.where(np.array(att_labels) != 1)[0])\n",
    "\n",
    "fixed_1_ix.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "fixed_test_size = 10\n",
    "\n",
    "fixed_1 = np.array(att_traces[fixed_1_ix])\n",
    "fixed_2 = np.array(att_traces[fixed_2_ix])\n",
    "\n",
    "len_fixed_1 = fixed_1.shape[0]\n",
    "fixed_1a = np.array(att_traces[fixed_1_ix][:round(len_fixed_1/2)])\n",
    "fixed_1b = np.array(att_traces[fixed_1_ix][round(len_fixed_1/2):])\n",
    "\n",
    "random_not_1 = np.array(att_traces[random_not_1_ix[:len_fixed_1]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "all_ixs = range(att_traces.shape[0])\n",
    "\n",
    "random_a_ix = sorted(np.random.choice(all_ixs, len_fixed_1, replace=False))\n",
    "random_b_ix = sorted(np.random.choice(all_ixs, len_fixed_1, replace=False))\n",
    "\n",
    "semi_random_b_ix = sorted(np.random.choice(list(set(all_ixs).difference(set(random_a_ix))), len_fixed_1, replace=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "random_a = np.array(att_traces[random_a_ix])\n",
    "random_b = np.array(att_traces[random_b_ix])\n",
    "semi_random_b = np.array(att_traces[np.sort(semi_random_b_ix)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classical LA methods\n",
    "## $t$-test method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "def nonzero_bins(bins):\n",
    "    \"\"\"\n",
    "    Retrieves all bins for which at least one category has a non-zero value.\n",
    "\n",
    "    :param bins: a set of categories with bins corresponding to that category.\n",
    "    :return: the indexes of non-zero bins.\n",
    "    \"\"\"\n",
    "    nz_bins = []\n",
    "    for ix, a, b in zip(range(len(bins[0])), *bins):\n",
    "        if a == 0 and b == 0:\n",
    "            continue\n",
    "\n",
    "        nz_bins.append(ix)\n",
    "\n",
    "    return nz_bins"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "DEFAULT_INDEX = range(-128, 127)\n",
    "\n",
    "def extract_ctable(traces):\n",
    "    \"\"\"\n",
    "    Builds a contingency table from traces from the ASCAD dataset.\n",
    "\n",
    "    :param traces: the traces from which the contingency table should be constructed.\n",
    "    :return: the contingency table.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([Counter(bins) for bins in traces])\n",
    "    res = df.sum().sort_index().reindex(DEFAULT_INDEX, fill_value=0).values\n",
    "\n",
    "    return np.array(res, dtype=int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def starts_with(first, last, reverse=False):\n",
    "    last += 1\n",
    "\n",
    "    ls = range(first, last)\n",
    "    if reverse:\n",
    "        reversed(ls)\n",
    "\n",
    "    return dict(zip(ls, [0] * len(list(ls))))\n",
    "\n",
    "def sample_mean(trace: np.array):\n",
    "    return trace.sum() / len(trace)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def values(trace):\n",
    "    return np.mean(trace), np.var(trace), len(trace)\n",
    "\n",
    "def test_statistic(mean_0, var_0, car_0, mean_1, var_1, car_1):\n",
    "    return (mean_0 - mean_1) / math.sqrt(var_0 / car_0 + var_1 / car_1)\n",
    "\n",
    "def degree_of_freedom(var_0, car_0, var_1, car_1):\n",
    "    nom = (var_0 / car_0 + var_1 / car_1)**2\n",
    "    den = (var_0 / car_0)**2 / (car_0 - 1) + (var_1 / car_1)**2 / (car_1 - 1)\n",
    "\n",
    "    return nom / den"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Student's t-probability distribution function\n",
    "import scipy.stats as stats\n",
    "\n",
    "def cdf(t, v):\n",
    "    \"\"\"\n",
    "    The cumulative distribution function as described on page 3.\n",
    "\n",
    "    The aim of a t-test is to provide a quantitative value as a probability that the mean μ\n",
    "        of two sets are different.\n",
    "\n",
    "    :param t: the test statistic of the two traces.\n",
    "    :param v: the degree of freedom of the two traces.\n",
    "    :return: the cumulative distribution function.\n",
    "    \"\"\"\n",
    "    return 2 * stats.t(v).cdf(-abs(t))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scipy.special as special\n",
    "\n",
    "class TraceProcessor:\n",
    "    def __init__(self, order=1, prob=.01):\n",
    "        \"\"\"\n",
    "        TraceProcessor digests traces using incremental programming. This allows for t-testing\n",
    "        anywhere in the digestion process.\n",
    "\n",
    "        :param order: The order of t-test to be performed on the data. Defaults to 1 to accommodate\n",
    "            for the ASCAD dataset, which features first-order leakages in AES traces.\n",
    "        :param prob: The desired probability for the t-test to reject H0.\n",
    "        \"\"\"\n",
    "        self.order = order\n",
    "        self.prob = prob\n",
    "\n",
    "        # Maximal statistical order to be maintained\n",
    "        self.max_d = self.order + 1\n",
    "\n",
    "        # Store binomial coefficients for use in calculating the central sums\n",
    "        #   (Schneider & Moradi, 2016 - page 6 - formula 3).\n",
    "        self.binom = {}\n",
    "        for d in range(self.max_d):\n",
    "            self.binom[d] = {}\n",
    "            for k in range(self.max_d):\n",
    "                self.binom[d][k] = special.binom(self.max_d, k)\n",
    "\n",
    "        # Central Moments (CM) to be maintained.\n",
    "        self.CM = starts_with(1, self.max_d)\n",
    "\n",
    "        # Central Sums (CS) to be maintained, corresponding to the CMs.\n",
    "        # CS is reversed to accommodate the update style of the CS (high to low).\n",
    "        self.CS = starts_with(2, self.max_d, reverse=True)\n",
    "\n",
    "        # Number of collected traces.\n",
    "        self.n = 0\n",
    "        # Cardinality of all observed traces combined.\n",
    "        self.cardinality = 0\n",
    "\n",
    "    def add_trace(self, trace: np.array):\n",
    "        \"\"\"\n",
    "        Adds traces and computes intermediate central moments.\n",
    "\n",
    "        :param trace: should be a numpy array containing the trace.\n",
    "        \"\"\"\n",
    "        # Please note that n = cardinality Q' in all central moment calculations,\n",
    "        #   where Q' is the trace set updated with the given trace.\n",
    "        self.n += 1\n",
    "        self.cardinality += len(trace)\n",
    "\n",
    "        # Second half of Schneider & Moradi, 2016 - page 6 - formula 3 is incompatible with n == 1,\n",
    "        #   due to the division by n - 1.\n",
    "        if self.n <= 1:\n",
    "            return\n",
    "\n",
    "        # Assuming here that y is the sample mean of the new trace\n",
    "        #   (Schneider & Moradi, 2016 - page 5 - bottom right)\n",
    "        #   This is not specified in their paper, which merely states y as \"trace\".\n",
    "        #   My assumption is based on the further calculations using delta as a number,\n",
    "        #   where delta should be a vector of variable length without this assumption.\n",
    "        delta = sample_mean(trace) - self.CM[1]\n",
    "\n",
    "        for central_sum_order in self.CS:\n",
    "            self.update_cs(central_sum_order, delta)\n",
    "\n",
    "        for central_moment_order in self.CM:\n",
    "            self.update_cm(central_moment_order, delta)\n",
    "\n",
    "    def update_cm(self, d, delta):\n",
    "        \"\"\"\n",
    "        Updates the Central Moment (CM) for a given order of central moment.\n",
    "\n",
    "        :param d: Central Moment order.\n",
    "        :param delta: the delta of the new trace (Schneider & Moradi, 2016 - page 5 - bottom left).\n",
    "        \"\"\"\n",
    "        if d == 1:\n",
    "            # Schneider & Moradi, 2016 - page 5 - bottom right.\n",
    "            self.CM[1] += delta / self.n\n",
    "        else:\n",
    "            # Schneider & Moradi, 2016 - page 6 - top left.\n",
    "            self.CM[d] = self.CS[d] / self.n\n",
    "\n",
    "    def update_cs(self, d, delta):\n",
    "        \"\"\"\n",
    "        Updates the Central Sum (CS) for a given order of central moment.\n",
    "\n",
    "        :param d: Central Moment order.\n",
    "        :param delta: the delta of the new trace (See page 5 bottom left).\n",
    "        \"\"\"\n",
    "        sum_prev_cs = 0\n",
    "        # Schneider & Moradi, 2016 - page 6 - formula 3.\n",
    "        for k in range(2, d - 2):\n",
    "            # As CS is reversed, this will access the lower-order central sums\n",
    "            #   which are not yet updated with the new trace.\n",
    "            sum_prev_cs += self.binom[d][k] * self.CS[d-k] * (-delta / self.n) ** k\n",
    "\n",
    "        a = (((self.n - 1) / self.n) * delta) ** d\n",
    "        b = 1 - (-1 / (self.n - 1)) ** (d - 1)\n",
    "\n",
    "        self.CS[d] += sum_prev_cs + a * b\n",
    "\n",
    "    def t_test(self, trace):\n",
    "        \"\"\"\n",
    "        Returns whether to reject H0. H0 being \"left and right are from different distributions\".\n",
    "        The traces should be normally distributed for the Student's t-test to work.\n",
    "\n",
    "        :param trace: the trace under test.\n",
    "        :return: whether H0 can be rejected.\n",
    "        \"\"\"\n",
    "        # Note that the first-order Central Moment (CM[1]) corresponds to the mean and\n",
    "        #   the second-order (CM[2]) to the variance.\n",
    "        mean, var, car = values(trace)\n",
    "\n",
    "        t = test_statistic(self.CM[1], self.CM[2], self.cardinality, mean, var, car)\n",
    "        v = degree_of_freedom(self.CM[2], self.cardinality, var, car)\n",
    "\n",
    "        # if t > 4.5 and v > 1000:\n",
    "        #     # Schneider & Moradi, 2016 - page 3 - bottom left.\n",
    "        #     return True\n",
    "\n",
    "        return cdf(t, v)\n",
    "\n",
    "tp = TraceProcessor()\n",
    "for trc in fixed_1:\n",
    "    tp.add_trace(trc)\n",
    "\n",
    "num_trc = 100\n",
    "\n",
    "sp_1 = 0\n",
    "for trc in fixed_1[:num_trc]:\n",
    "    sp_1 += tp.t_test(trc)\n",
    "\n",
    "sp_2 = 0\n",
    "for trc in fixed_2[:num_trc]:\n",
    "    sp_2 += tp.t_test(trc)\n",
    "\n",
    "print(sp_1 / num_trc)\n",
    "print(sp_2 / num_trc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def calc_t(H):\n",
    "    mean, var, n = [[0, 0]] * 3\n",
    "    nz_bins = nonzero_bins(H)\n",
    "\n",
    "    for ix_cat in range(2):\n",
    "        for ix_bin in nz_bins:\n",
    "            item = H[ix_cat][ix_bin]\n",
    "            # mean[ix_cat] += H[ix_cat][ix_bin] * range_h[ix_bin]\n",
    "            mean[ix_cat] += item\n",
    "            n[ix_cat] += item\n",
    "\n",
    "        mean[ix_cat] /= n[ix_cat]\n",
    "\n",
    "        for ix_bin in nz_bins:\n",
    "            # tmp = (range_h[ix_bin] - mean[ix_cat])\n",
    "            tmp = mean[ix_cat]\n",
    "            # print(tmp)\n",
    "            var[ix_cat] += tmp ** 2 + H[ix_cat][ix_bin]\n",
    "\n",
    "        var[ix_cat] /= n[ix_cat]\n",
    "\n",
    "    # t-value\n",
    "    mean_diff = mean[0] - mean[1]\n",
    "    var_sum = (var[0] / n[0]) + (var[1] / n[1])\n",
    "\n",
    "    print(var_sum)\n",
    "    return\n",
    "    t_ret = mean_diff / math.sqrt(var_sum)\n",
    "\n",
    "    # degree of freedom\n",
    "    denom = ((var[0] / n[0]) * (var[0] / n[0])) / (n[0] - 1) + ((var[1] / n[1]) * (var[1] / n[1])) / (n[1] - 1)\n",
    "    t_dof_ret = var_sum ** 2 / denom\n",
    "\n",
    "    # cdf\n",
    "    t_p_ret = 2 * stats.t(t_dof_ret).cdf(-abs(t_ret))\n",
    "\n",
    "    return t_ret, t_dof_ret, t_p_ret\n",
    "\n",
    "# TODO do not use the ctable!\n",
    "\n",
    "calc_t(fixed_1[:2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calc_t([extract_ctable(fixed_1), extract_ctable(fixed_1)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## $\\chi^2$ method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "def calc_chi(ctable):\n",
    "    \"\"\"\n",
    "    Calculates the p value for rejecting H0, among others.\n",
    "    Small p values give evidence to reject the null hypothesis and conclude that for the\n",
    "    scenarios presented in ctable the occurrences of the observations are not independent.\n",
    "\n",
    "    :param ctable: contingency table for different categories of traces.\n",
    "    :return: A 3-tuple containing: The value for chi, the degrees of freedom,\n",
    "        the p value for rejecting H0.\n",
    "    \"\"\"\n",
    "    num_cats = len(ctable)\n",
    "    num_bins = len(ctable[0])\n",
    "\n",
    "    # chi**2 value\n",
    "    sum_rows = [0] * num_cats\n",
    "    sum_cols = [0] * num_bins\n",
    "    N = 0.0\n",
    "\n",
    "    # Only check non-zero bins\n",
    "    nz_bins = nonzero_bins(ctable)\n",
    "\n",
    "    for ix_bin in nz_bins:\n",
    "        for ix_cat in range(num_cats):\n",
    "            # Bin from the contingency table\n",
    "            c_bin = ctable[ix_cat][ix_bin]\n",
    "\n",
    "            sum_rows[ix_cat] += c_bin\n",
    "            sum_cols[ix_bin] += c_bin\n",
    "            N += c_bin\n",
    "\n",
    "    chi = 0.0\n",
    "    for ix_bin in nz_bins:\n",
    "        for ix_cat in range(num_cats):\n",
    "            E = (sum_rows[ix_cat] * sum_cols[ix_bin]) / N\n",
    "            tmp = (ctable[ix_cat][ix_bin] - E)\n",
    "\n",
    "            chi += tmp ** 2 / E\n",
    "\n",
    "    # Degrees of freedom\n",
    "    dof = (num_bins - 1) * (num_cats - 1)\n",
    "    # p-value for rejecting H0\n",
    "    p = stats.chi2(dof).cdf(chi)\n",
    "\n",
    "    return chi, dof, p"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "def p_value_chi(a, b):\n",
    "    print(f\"p-value: {calc_chi([extract_ctable(a), extract_ctable(b)])[2]:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "fixed_1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-23, -26, -29, ..., -84, -86, -85],\n       [-21, -25, -29, ..., -85, -84, -86],\n       [-20, -24, -29, ..., -86, -85, -86],\n       ...,\n       [-21, -21, -25, ..., -84, -84, -85],\n       [-20, -26, -29, ..., -84, -85, -85],\n       [-21, -21, -26, ..., -85, -85, -85]], dtype=int8)"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-21, -25, -29, ..., -85, -86, -86],\n       [-20, -21, -25, ..., -85, -85, -86],\n       [-22, -25, -28, ..., -84, -85, -86],\n       ...,\n       [-20, -23, -29, ..., -85, -87, -86],\n       [-20, -23, -29, ..., -85, -86, -86],\n       [-22, -23, -26, ..., -84, -85, -84]], dtype=int8)"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "cases = {\n",
    "    \"Fixed vs. fixed, equal traces.\": (fixed_1, fixed_1),\n",
    "    \"Fixed vs. fixed, equal key.\": (fixed_1a, fixed_1b),\n",
    "    \"Fixed vs. fixed, different key.\": (fixed_1, fixed_2),\n",
    "    \"Fixed vs. semi-random (fixed key is not in random sample).\": (fixed_1, random_not_1),\n",
    "    \"Fixed vs. random.\": (fixed_1, random_b),\n",
    "    \"Random vs. random.\": (random_a, random_b),\n",
    "    \"Random vs. semi-random\": (random_a, semi_random_b)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "cases_chi = {\n",
    "    \"Scenario\": list(cases.keys()),\n",
    "    \"p-value\": [f\"{calc_chi([extract_ctable(a), extract_ctable(b)])[2]:.3f}\" for a, b in cases.values()]\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Examples for $\\chi^2$ on different scenarios.\n",
    "Small p-values give reason to reject $H_0$ =\n",
    "\"the occurrences of these observations are independent\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            Scenario p-value\n0                     Fixed vs. fixed, equal traces.   0.000\n1                        Fixed vs. fixed, equal key.   0.204\n2                    Fixed vs. fixed, different key.   0.997\n3  Fixed vs. semi-random (fixed key is not in ran...   0.120\n4                                  Fixed vs. random.   1.000\n5                                 Random vs. random.   0.108\n6                             Random vs. semi-random   1.000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Scenario</th>\n      <th>p-value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Fixed vs. fixed, equal traces.</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Fixed vs. fixed, equal key.</td>\n      <td>0.204</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Fixed vs. fixed, different key.</td>\n      <td>0.997</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Fixed vs. semi-random (fixed key is not in ran...</td>\n      <td>0.120</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Fixed vs. random.</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Random vs. random.</td>\n      <td>0.108</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Random vs. semi-random</td>\n      <td>1.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cases_chi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}