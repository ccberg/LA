{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SCA using hamming weight for classification.\n",
    "\n",
    "Example from [here]() TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.backend import clear_session\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.utils import *\n",
    "\n",
    "from src.data.preprocess.hw import hamming_weights\n",
    "from src.tools.plotter import init_plots\n",
    "from src.trace_set.database import Database\n",
    "from src.trace_set.pollution import PollutionType, Pollution\n",
    "from src.trace_set.set_hw import TraceSetHW\n",
    "\n",
    "init_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_z_score_norm(dataset):\n",
    "    z_score_mean = np.mean(dataset, axis=0)\n",
    "    z_score_std = np.std(dataset, axis=0)\n",
    "    return z_score_mean, z_score_std\n",
    "\n",
    "\n",
    "def apply_z_score_norm(dataset, z_score_mean, z_score_std):\n",
    "    for index in range(len(dataset)):\n",
    "        dataset[index] = (dataset[index] - z_score_mean) / z_score_std\n",
    "\n",
    "\n",
    "def mlp(classes, number_of_samples):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape=(number_of_samples,)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "AES_Sbox = np.array([\n",
    "    0x63, 0x7C, 0x77, 0x7B, 0xF2, 0x6B, 0x6F, 0xC5, 0x30, 0x01, 0x67, 0x2B, 0xFE, 0xD7, 0xAB, 0x76,\n",
    "    0xCA, 0x82, 0xC9, 0x7D, 0xFA, 0x59, 0x47, 0xF0, 0xAD, 0xD4, 0xA2, 0xAF, 0x9C, 0xA4, 0x72, 0xC0,\n",
    "    0xB7, 0xFD, 0x93, 0x26, 0x36, 0x3F, 0xF7, 0xCC, 0x34, 0xA5, 0xE5, 0xF1, 0x71, 0xD8, 0x31, 0x15,\n",
    "    0x04, 0xC7, 0x23, 0xC3, 0x18, 0x96, 0x05, 0x9A, 0x07, 0x12, 0x80, 0xE2, 0xEB, 0x27, 0xB2, 0x75,\n",
    "    0x09, 0x83, 0x2C, 0x1A, 0x1B, 0x6E, 0x5A, 0xA0, 0x52, 0x3B, 0xD6, 0xB3, 0x29, 0xE3, 0x2F, 0x84,\n",
    "    0x53, 0xD1, 0x00, 0xED, 0x20, 0xFC, 0xB1, 0x5B, 0x6A, 0xCB, 0xBE, 0x39, 0x4A, 0x4C, 0x58, 0xCF,\n",
    "    0xD0, 0xEF, 0xAA, 0xFB, 0x43, 0x4D, 0x33, 0x85, 0x45, 0xF9, 0x02, 0x7F, 0x50, 0x3C, 0x9F, 0xA8,\n",
    "    0x51, 0xA3, 0x40, 0x8F, 0x92, 0x9D, 0x38, 0xF5, 0xBC, 0xB6, 0xDA, 0x21, 0x10, 0xFF, 0xF3, 0xD2,\n",
    "    0xCD, 0x0C, 0x13, 0xEC, 0x5F, 0x97, 0x44, 0x17, 0xC4, 0xA7, 0x7E, 0x3D, 0x64, 0x5D, 0x19, 0x73,\n",
    "    0x60, 0x81, 0x4F, 0xDC, 0x22, 0x2A, 0x90, 0x88, 0x46, 0xEE, 0xB8, 0x14, 0xDE, 0x5E, 0x0B, 0xDB,\n",
    "    0xE0, 0x32, 0x3A, 0x0A, 0x49, 0x06, 0x24, 0x5C, 0xC2, 0xD3, 0xAC, 0x62, 0x91, 0x95, 0xE4, 0x79,\n",
    "    0xE7, 0xC8, 0x37, 0x6D, 0x8D, 0xD5, 0x4E, 0xA9, 0x6C, 0x56, 0xF4, 0xEA, 0x65, 0x7A, 0xAE, 0x08,\n",
    "    0xBA, 0x78, 0x25, 0x2E, 0x1C, 0xA6, 0xB4, 0xC6, 0xE8, 0xDD, 0x74, 0x1F, 0x4B, 0xBD, 0x8B, 0x8A,\n",
    "    0x70, 0x3E, 0xB5, 0x66, 0x48, 0x03, 0xF6, 0x0E, 0x61, 0x35, 0x57, 0xB9, 0x86, 0xC1, 0x1D, 0x9E,\n",
    "    0xE1, 0xF8, 0x98, 0x11, 0x69, 0xD9, 0x8E, 0x94, 0x9B, 0x1E, 0x87, 0xE9, 0xCE, 0x55, 0x28, 0xDF,\n",
    "    0x8C, 0xA1, 0x89, 0x0D, 0xBF, 0xE6, 0x42, 0x68, 0x41, 0x99, 0x2D, 0x0F, 0xB0, 0x54, 0xBB, 0x16\n",
    "])\n",
    "\n",
    "ASCAD_data_folder = \"/data/ASCAD/ATMEGA_AES_v1/ATM_AES_v1_variable_key/ASCAD_data/ASCAD_databases/\"\n",
    "\n",
    "with h5py.File(ASCAD_data_folder + \"ASCAD_variable.h5\", \"r\") as in_file:\n",
    "    attack_plaintext = in_file['Attack_traces/metadata']['plaintext']\n",
    "    attack_key = in_file['Attack_traces/metadata']['key']\n",
    "    attack_data = np.zeros((100000, 32))\n",
    "    for i in range(100000):\n",
    "        attack_data[i][0:16] = attack_plaintext[i]\n",
    "        attack_data[i][16:32] = attack_key[i]\n",
    "\n",
    "def aes_labelize_ge_sr(plt_attack, byte, key, leakage):\n",
    "    pt_ct = [row[byte] for row in plt_attack]\n",
    "\n",
    "    key_byte = np.full(len(pt_ct), key[byte])\n",
    "    state = [int(x) ^ int(k) for x, k in zip(np.asarray(pt_ct[:]), key_byte)]\n",
    "\n",
    "    intermediate_values = AES_Sbox[state]\n",
    "\n",
    "    if leakage == \"HW\":\n",
    "        return [bin(iv).count(\"1\") for iv in intermediate_values]\n",
    "    else:\n",
    "        return intermediate_values\n",
    "\n",
    "# guessing entropy and success rate\n",
    "def compute_ge(runs, model, key, correct_key, leakage_model, byte, x_attack, plt_attack, key_rank_report_interval, key_rank_attack_traces):\n",
    "    nt = len(x_attack)\n",
    "    nt_interval = int(key_rank_attack_traces / key_rank_report_interval)\n",
    "    key_ranking_sum = np.zeros(nt_interval)\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------------#\n",
    "    # compute labels for key hypothesis\n",
    "    # ---------------------------------------------------------------------------------------------------------#\n",
    "    labels_key_hypothesis = np.zeros((256, nt))\n",
    "    for key_byte_hypothesis in range(0, 256):\n",
    "        key_h = bytearray.fromhex(key)\n",
    "        key_h[byte] = key_byte_hypothesis\n",
    "\n",
    "        labels_key_hypothesis[key_byte_hypothesis] = aes_labelize_ge_sr(plt_attack, byte, key_h, leakage_model)\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------------#\n",
    "    # predict output probabilities for shuffled test or validation set\n",
    "    # ---------------------------------------------------------------------------------------------------------#\n",
    "    output_probabilities = model.predict(x_attack)\n",
    "\n",
    "    probabilities_kg_all_traces = np.zeros((nt, 256))\n",
    "    for index in range(nt):\n",
    "        probabilities_kg_all_traces[index] = output_probabilities[index][\n",
    "            np.asarray([int(leakage[index]) for leakage in labels_key_hypothesis[:]])\n",
    "        ]\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------------#\n",
    "    # run key rank \"runs\" times and average results.\n",
    "    # ---------------------------------------------------------------------------------------------------------#\n",
    "    for run in range(runs):\n",
    "\n",
    "        probabilities_kg_all_traces_shuffled = shuffle(probabilities_kg_all_traces,\n",
    "                                                       random_state=random.randint(0, 100000))\n",
    "\n",
    "        key_probabilities = np.zeros(256)\n",
    "\n",
    "        kr_count = 0\n",
    "        for index in range(key_rank_attack_traces):\n",
    "\n",
    "            key_probabilities += np.log(probabilities_kg_all_traces_shuffled[index] + 1e-36)\n",
    "            key_probabilities_sorted = np.argsort(key_probabilities)[::-1]\n",
    "\n",
    "            if (index + 1) % key_rank_report_interval == 0:\n",
    "                key_ranking_good_key = list(key_probabilities_sorted).index(correct_key) + 1\n",
    "                key_ranking_sum[kr_count] += key_ranking_good_key\n",
    "                kr_count += 1\n",
    "\n",
    "        print(\"KR run: {} | final GE for correct key ({}): {})\".format(run, correct_key, key_ranking_sum[nt_interval - 1] / (run + 1)))\n",
    "\n",
    "    guessing_entropy = key_ranking_sum / runs\n",
    "\n",
    "    return guessing_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def store_results(database: Database, method: str, pollution: Pollution, ge: int):\n",
    "    file_name = f\"results_{database.name}.csv\"\n",
    "    with open(file_name, 'a') as f:\n",
    "        f.write(f\"{method};{pollution.type.name};{pollution.parameter};{ge}\\n\")\n",
    "\n",
    "def get_ge(db: Database, pollution: Pollution, do_plot=False):\n",
    "    l_model = \"HW\"\n",
    "    classes = 9\n",
    "    target_byte = 2\n",
    "    ns = 1400\n",
    "    correct_key = 34\n",
    "    key = \"00112233445566778899AABBCCDDEEFF\"\n",
    "\n",
    "    # Load the profiling traces\n",
    "    trace_set = TraceSetHW(db, pollution)\n",
    "    (X_PROF, STATES_PROF), (X_ATT, STATES_ATT) = trace_set.profile_states(), trace_set.attack_states()\n",
    "\n",
    "    hw_prof = hamming_weights(STATES_PROF)\n",
    "    hw_att = hamming_weights(STATES_ATT)\n",
    "\n",
    "    # normalize with z-score\n",
    "    z_score_mean, z_score_std = create_z_score_norm(X_PROF)\n",
    "    apply_z_score_norm(X_PROF, z_score_mean, z_score_std)\n",
    "    apply_z_score_norm(X_ATT, z_score_mean, z_score_std)\n",
    "\n",
    "    x_profiling = X_PROF.astype('float32')\n",
    "    x_attack = X_ATT.astype('float32')\n",
    "\n",
    "    # convert labels to categorical labels\n",
    "    y_profiling = to_categorical(hw_prof, num_classes=classes)\n",
    "    y_attack = to_categorical(hw_att, num_classes=classes)\n",
    "\n",
    "    # train MLP\n",
    "    model = mlp(classes, ns)\n",
    "\n",
    "    model.fit(x=x_profiling, y=y_profiling, batch_size=150, verbose=1, epochs=5, shuffle=True,\n",
    "              validation_data=(x_attack, y_attack), callbacks=[])\n",
    "\n",
    "    key_rank_report_interval = 1\n",
    "    key_rank_number_of_traces = len(hw_att)\n",
    "    key_rank_runs = 10\n",
    "\n",
    "    ge = compute_ge(key_rank_runs, model, key, correct_key, l_model, target_byte, X_ATT, attack_data, key_rank_report_interval,\n",
    "                    key_rank_number_of_traces)\n",
    "\n",
    "\n",
    "    if do_plot:\n",
    "        plt.plot(np.arange(1, key_rank_number_of_traces + 1), ge, label=\"GE\")\n",
    "        plt.xlabel(\"Traces\")\n",
    "        plt.ylabel(\"Guessing Entropy\")\n",
    "        plt.xlim([0, key_rank_number_of_traces])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    print(f\"{pollution.get_name()}: ge=({ge[-1]})\")\n",
    "    store_results(db, \"sca_hw\", pollution, ge[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KR run: 2 | final GE for correct key (34): 3.0)\n",
      "KR run: 3 | final GE for correct key (34): 3.0)\n",
      "KR run: 4 | final GE for correct key (34): 3.0)\n",
      "KR run: 5 | final GE for correct key (34): 3.0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-6a9ce650498e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mTRS\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m             \u001B[0mget_ge\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDB\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mPOLL\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-4-03e5105ff249>\u001B[0m in \u001B[0;36mget_ge\u001B[0;34m(db, pollution, do_plot)\u001B[0m\n\u001B[1;32m     41\u001B[0m     \u001B[0mkey_rank_runs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m10\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 43\u001B[0;31m     ge = compute_ge(key_rank_runs, model, key, correct_key, l_model, target_byte, X_ATT, attack_data, key_rank_report_interval,\n\u001B[0m\u001B[1;32m     44\u001B[0m                     key_rank_number_of_traces)\n\u001B[1;32m     45\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-3-680637f20cf6>\u001B[0m in \u001B[0;36mcompute_ge\u001B[0;34m(runs, model, key, correct_key, leakage_model, byte, x_attack, plt_attack, key_rank_report_interval, key_rank_attack_traces)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m             \u001B[0mkey_probabilities\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprobabilities_kg_all_traces_shuffled\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1e-36\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 84\u001B[0;31m             \u001B[0mkey_probabilities_sorted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margsort\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey_probabilities\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     85\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mkey_rank_report_interval\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<__array_function__ internals>\u001B[0m in \u001B[0;36margsort\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/LA/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001B[0m in \u001B[0;36margsort\u001B[0;34m(a, axis, kind, order)\u001B[0m\n\u001B[1;32m   1110\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1111\u001B[0m     \"\"\"\n\u001B[0;32m-> 1112\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_wrapfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'argsort'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkind\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkind\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1113\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1114\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/LA/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001B[0m in \u001B[0;36m_wrapfunc\u001B[0;34m(obj, method, *args, **kwds)\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mbound\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     59\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m         \u001B[0;31m# A TypeError occurs if the object does have such a method in its\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "DB = Database.ascad\n",
    "POLL_TYPE = PollutionType.gauss\n",
    "GAUSS_PARAMS = np.arange(0, 41, 1)\n",
    "\n",
    "while True:\n",
    "    for PARAM in GAUSS_PARAMS:\n",
    "        print(f\"Calculating GE for {PARAM}\")\n",
    "        POLL = Pollution(POLL_TYPE, PARAM)\n",
    "        TRS = TraceSetHW(DB, POLL)\n",
    "\n",
    "        if os.path.exists(TRS.path):\n",
    "            get_ge(DB, POLL)\n",
    "            clear_session()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}