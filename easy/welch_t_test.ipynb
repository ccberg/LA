{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def starts_with(first, last, reverse=False):\n",
    "    last += 1\n",
    "\n",
    "    ls = range(first, last)\n",
    "    if reverse:\n",
    "        reversed(ls)\n",
    "\n",
    "    return dict(zip(ls, [0] * len(list(ls))))\n",
    "\n",
    "def sample_mean(trace: np.array):\n",
    "    return trace.sum() / len(trace)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def values(trace):\n",
    "    return np.mean(trace), np.var(trace), len(trace)\n",
    "\n",
    "def test_statistic(mean_0, var_0, car_0, mean_1, var_1, car_1):\n",
    "    return (mean_0 - mean_1) / math.sqrt(var_0 / car_0 + var_1 / car_1)\n",
    "\n",
    "def degree_of_freedom(var_0, car_0, var_1, car_1):\n",
    "    nom = (var_0 / car_0 + var_1 / car_1)**2\n",
    "    den = (var_0 / car_0)**2 / (car_0 - 1) + (var_1 / car_1)**2 / (car_1 - 1)\n",
    "\n",
    "    return nom / den"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Student's t-probability distribution function\n",
    "import scipy.stats as stats\n",
    "\n",
    "def cdf(t, v):\n",
    "    \"\"\"\n",
    "    The cumulative distribution function as described on page 3.\n",
    "\n",
    "    The aim of a t-test is to provide a quantitative value as a probability that the mean Î¼\n",
    "        of two sets are different.\n",
    "\n",
    "    :param t: the test statistic of the two traces.\n",
    "    :param v: the degree of freedom of the two traces.\n",
    "    :return: the cumulative distribution function.\n",
    "    \"\"\"\n",
    "    return 2 * stats.t(v).cdf(-abs(t))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.special as special\n",
    "\n",
    "special.binom(7, 3) == 35"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class TraceProcessor:\n",
    "    def __init__(self, order=1, prob=.01):\n",
    "        \"\"\"\n",
    "        TraceProcessor digests traces using incremental programming. This allows for t-testing\n",
    "        anywhere in the digestion process.\n",
    "\n",
    "        :param order: The order of t-test to be performed on the data. Defaults to 1 to accommodate\n",
    "            for the ASCAD dataset, which features first-order leakages in AES traces.\n",
    "        :param prob: The desired probability for the t-test to reject H0.\n",
    "        \"\"\"\n",
    "        self.order = order\n",
    "        self.prob = prob\n",
    "\n",
    "        # Maximal statistical order to be maintained\n",
    "        self.max_d = self.order + 1\n",
    "\n",
    "        # Store binomial coefficients for use in calculating the central sums\n",
    "        #   (Schneider & Moradi, 2016 - page 6 - formula 3).\n",
    "        self.binom = {}\n",
    "        for d in range(self.max_d):\n",
    "            self.binom[d] = {}\n",
    "            for k in range(self.max_d):\n",
    "                self.binom[d][k] = special.binom(self.max_d, k)\n",
    "\n",
    "        # Central Moments (CM) to be maintained.\n",
    "        self.CM = starts_with(1, self.max_d)\n",
    "\n",
    "        # Central Sums (CS) to be maintained, corresponding to the CMs.\n",
    "        # CS is reversed to accommodate the update style of the CS (high to low).\n",
    "        self.CS = starts_with(2, self.max_d, reverse=True)\n",
    "\n",
    "        # Number of collected traces.\n",
    "        self.n = 0\n",
    "        # Cardinality of all observed traces combined.\n",
    "        self.cardinality = 0\n",
    "\n",
    "    def add_trace(self, trace: np.array):\n",
    "        \"\"\"\n",
    "        Adds traces and computes intermediate central moments.\n",
    "\n",
    "        :param trace: should be a numpy array containing the trace.\n",
    "        \"\"\"\n",
    "        # Please note that n = cardinality Q' in all central moment calculations,\n",
    "        #   where Q' is the trace set updated with the given trace.\n",
    "        self.n += 1\n",
    "        self.cardinality += len(trace)\n",
    "\n",
    "        # Second half of Schneider & Moradi, 2016 - page 6 - formula 3 is incompatible with n == 1,\n",
    "        #   due to the division by n - 1.\n",
    "        if self.n <= 1:\n",
    "            return\n",
    "\n",
    "        # Assuming here that y is the sample mean of the new trace\n",
    "        #   (Schneider & Moradi, 2016 - page 5 - bottom right)\n",
    "        #   This is not specified in their paper, which merely states y as \"trace\".\n",
    "        #   My assumption is based on the further calculations using delta as a number,\n",
    "        #   where delta should be a vector of variable length without this assumption.\n",
    "        delta = sample_mean(trace) - self.CM[1]\n",
    "\n",
    "        for central_sum_order in self.CS:\n",
    "            self.update_cs(central_sum_order, delta)\n",
    "\n",
    "        for central_moment_order in self.CM:\n",
    "            self.update_cm(central_moment_order, delta)\n",
    "\n",
    "    def update_cm(self, d, delta):\n",
    "        \"\"\"\n",
    "        Updates the Central Moment (CM) for a given order of central moment.\n",
    "\n",
    "        :param d: Central Moment order.\n",
    "        :param delta: the delta of the new trace (Schneider & Moradi, 2016 - page 5 - bottom left).\n",
    "        \"\"\"\n",
    "        if d == 1:\n",
    "            # Schneider & Moradi, 2016 - page 5 - bottom right.\n",
    "            self.CM[1] += delta / self.n\n",
    "        else:\n",
    "            # Schneider & Moradi, 2016 - page 6 - top left.\n",
    "            self.CM[d] = self.CS[d] / self.n\n",
    "\n",
    "    def update_cs(self, d, delta):\n",
    "        \"\"\"\n",
    "        Updates the Central Sum (CS) for a given order of central moment.\n",
    "\n",
    "        :param d: Central Moment order.\n",
    "        :param delta: the delta of the new trace (See page 5 bottom left).\n",
    "        \"\"\"\n",
    "        sum_prev_cs = 0\n",
    "        # Schneider & Moradi, 2016 - page 6 - formula 3.\n",
    "        for k in range(2, d - 2):\n",
    "            # As CS is reversed, this will access the lower-order central sums\n",
    "            #   which are not yet updated with the new trace.\n",
    "            sum_prev_cs += self.binom[d][k] * self.CS[d-k] * (-delta / self.n) ** k\n",
    "\n",
    "        a = (((self.n - 1) / self.n) * delta) ** d\n",
    "        b = 1 - (-1 / (self.n - 1)) ** (d - 1)\n",
    "\n",
    "        self.CS[d] += sum_prev_cs + a * b\n",
    "\n",
    "    def t_test(self, trace):\n",
    "        \"\"\"\n",
    "        Returns whether to reject H0. H0 being \"left and right are from different distributions\".\n",
    "        The traces should be normally distributed for the Student's t-test to work.\n",
    "\n",
    "        :param trace: the trace under test.\n",
    "        :return: whether H0 can be rejected.\n",
    "        \"\"\"\n",
    "        # Note that the first-order Central Moment (CM[1]) corresponds to the mean and\n",
    "        #   the second-order (CM[2]) to the variance.\n",
    "        mean, var, car = values(trace)\n",
    "\n",
    "        t = test_statistic(self.CM[1], self.CM[2], self.cardinality, mean, var, car)\n",
    "        v = degree_of_freedom(self.CM[2], self.cardinality, var, car)\n",
    "        if t > 4.5 and v > 1000:\n",
    "            # Schneider & Moradi, 2016 - page 3 - bottom left.\n",
    "            return True\n",
    "\n",
    "        return cdf(t, v) < self.prob"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calc_t(H):\n",
    "    mean = [0, 0]\n",
    "    var = [0, 0]\n",
    "    n = [0, 0]\n",
    "\n",
    "    for ix_cat in range(2):\n",
    "        for ix_bin in range(len(H[ix_cat])):\n",
    "            # mean[ix_cat] += H[ix_cat][ix_bin] * range[ix_bin]\n",
    "            mean[ix_cat] += H[ix_cat][ix_bin]\n",
    "            n[ix_cat] += H[ix_cat][ix_bin]\n",
    "\n",
    "        mean[ix_cat] /= n[ix_cat]\n",
    "\n",
    "        for ix_bin in range(len(H[ix_cat])):\n",
    "            # tmp = (range[ix_bin] - mean[ix_cat])\n",
    "            tmp = mean[ix_cat]\n",
    "            var[ix_cat] += tmp ** 2 + H[ix_cat][ix_bin]\n",
    "\n",
    "        var[ix_cat] /= n[ix_cat]\n",
    "\n",
    "    # t-value\n",
    "    mean_diff = mean[0] - mean[1]\n",
    "    var_sum = (var[0] / n[0]) + (var[1] / n[1])\n",
    "    t_ret = mean_diff / math.sqrt(var_sum)\n",
    "\n",
    "    # degree of freedom\n",
    "    denom = ((var[0] / n[0]) * (var[0] / n[0])) / (n[0] - 1) + ((var[1] / n[1]) * (var[1] / n[1])) / (n[1] - 1)\n",
    "    t_dof_ret = var_sum ** 2 / denom\n",
    "\n",
    "    # cdf\n",
    "    t_p_ret = cdf(t_ret, t_dof_ret)\n",
    "\n",
    "    return t_ret, t_dof_ret, t_p_ret"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def calc_chi(H):\n",
    "    num_cats = len(H)\n",
    "    num_bins = len(H[0])\n",
    "\n",
    "    # Degrees of freedom\n",
    "    chi_dof_ret = (num_bins - 1) * (num_cats - 1)\n",
    "\n",
    "    # chi**2 value\n",
    "    sum_rows = [0] * num_cats\n",
    "    sum_cols = [0] * num_bins\n",
    "    N = 0.0\n",
    "\n",
    "    for ix_bin in range(num_bins):\n",
    "        for ix_cat in range(num_cats):\n",
    "            sum_rows[ix_cat] += H[ix_cat][ix_bin]\n",
    "            sum_cols[ix_bin] += H[ix_cat][ix_bin]\n",
    "            N += H[ix_cat][ix_bin]\n",
    "\n",
    "    chi_tmp = 0.0\n",
    "    for ix_bin in range(num_bins):\n",
    "        for ix_cat in range(num_cats):\n",
    "            E = (sum_rows[ix_cat] * sum_cols[ix_bin]) / N\n",
    "            tmp = (H[ix_cat][ix_bin] - E)\n",
    "\n",
    "            chi_tmp += tmp ** 2 / E\n",
    "\n",
    "    chi_ret = chi_tmp\n",
    "    chi_p_ret = stats.chi2(chi_tmp).cdf(chi_dof_ret)\n",
    "\n",
    "    # Small p values give evidence to reject the null hypothesis and conclude that for these\n",
    "    #   scenarios the occurrences of the observations are not independent\n",
    "    return chi_ret, chi_dof_ret, chi_p_ret"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 598.0, 1.0) (0.0, 99, nan)\n",
      "(0.0, 300.3350804540584, 1.0) (459.2465064314272, 99, 5.347906529608671e-77)\n"
     ]
    }
   ],
   "source": [
    "inpt = [np.random.normal(3, 0, 100), np.random.normal(3, 0, 100)]\n",
    "inpt1 = [np.random.normal(1000, 1000, 100), np.random.normal(3, 0, 100)]\n",
    "\n",
    "print(calc_t(inpt), calc_chi(inpt))\n",
    "print(calc_t(inpt1), calc_chi(inpt1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True\n"
     ]
    }
   ],
   "source": [
    "TRACE_TRAIN = [np.random.normal(3, 1, 1000) for _ in range(100)]\n",
    "\n",
    "TRACE_TEST_PASS = np.random.normal(3, 1, 1000)\n",
    "TRACE_TEST_REJECT = np.random.normal(5, .01, 1000)\n",
    "\n",
    "TP = TraceProcessor()\n",
    "for t in TRACE_TRAIN:\n",
    "    TP.add_trace(t)\n",
    "\n",
    "print(TP.t_test(TRACE_TEST_PASS), TP.t_test(TRACE_TEST_REJECT))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "0.07"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_fpr(tp: TraceProcessor, trace_set):\n",
    "    \"\"\"\n",
    "    Gets the False Positive Rate (FPR) over a set of traces.\n",
    "    Equal to the rate at which H0 is falsely accepted.\n",
    "\n",
    "    :param tp: The TraceProcessor, trained over a set of traces Q.\n",
    "    :param trace_set: Set of traces, which are drawn from a different distribution than Q.\n",
    "    :return: Returns the FPR over this set of traces.\n",
    "    \"\"\"\n",
    "    fp = 0\n",
    "    for trace in trace_set:\n",
    "        fp += 1 - tp.t_test(trace)\n",
    "\n",
    "    return fp / len(trace_set)\n",
    "\n",
    "get_fpr(TP, [np.random.normal(3.1, 1, 1000) for _ in range(100)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "0.04"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_fnr(tp: TraceProcessor, trace_set):\n",
    "    \"\"\"\n",
    "    Gets the False Negative Rate (FNR) over a given set of traces.\n",
    "    Equal to the rate at which H0 is falsely rejected.\n",
    "\n",
    "    :param tp: The TraceProcessor, trained over a set of traces Q.\n",
    "    :param trace_set: Set of traces, which are drawn from the same distribution as Q.\n",
    "    :return: Returns the FNR over this set of traces.\n",
    "    \"\"\"\n",
    "    fn = 0\n",
    "    for trace in trace_set:\n",
    "        fn += tp.t_test(trace)\n",
    "\n",
    "    return fn / len(trace_set)\n",
    "\n",
    "get_fnr(TP, [np.random.normal(3, 1, 1000) for _ in range(100)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}