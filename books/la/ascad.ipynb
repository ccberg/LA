{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Initial Hamming Weight experiment\n",
    "\n",
    "With brute-force hyper parameter optimization of the MLP."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.python.keras.optimizer_v2.adam import Adam\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "from src.data.ascad import AscadRandomKey\n",
    "from src.dlla.hw import NUM_CLASSES, fetch_traces, plot_predictions, dlla_hw, dlla_p_gradient, encode, split_traces\n",
    "from src.dlla.wegener import make_mlp_wegener, wegener_p_gradient\n",
    "from src.tools.cache import cache_np\n",
    "from src.tools.lists import random_divide, randomize\n",
    "from src.tools.plotter import init_plots, plot_p_gradient, PALETTE_GRADIENT, store_sns\n",
    "from src.trace_set.database import Database\n",
    "from src.trace_set.pollution import Pollution, PollutionType\n",
    "from src.trace_set.set_hw import TraceSetHW\n",
    "from src.trace_set.transform import reduce_fixed_fixed\n",
    "from src.tvla.cri import tvla_cri, tvla_cri_p_gradient\n",
    "from src.tvla.tvla import Tvla\n",
    "\n",
    "init_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DB = Database.ascad\n",
    "TRACE_SET = TraceSetHW(DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def prepare_traces_dl(x, y, x_att, y_att):\n",
    "    \"\"\"\n",
    "    Normalizes the traces, one-hot encodes the labels.\n",
    "    Returns profiling traces, labels and attack traces, labels.\n",
    "    \"\"\"\n",
    "    prof_mean, prof_std = x.mean(axis=0), x.std(axis=0)\n",
    "    norm_x = (x - prof_mean) / prof_std\n",
    "    norm_x_att = (x_att - prof_mean) / prof_std\n",
    "\n",
    "    return norm_x, encode(y), norm_x_att, encode(y_att)\n",
    "\n",
    "X, Y, X_ATT, Y_ATT = prepare_traces_dl(*TRACE_SET.profile(), *TRACE_SET.attack())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TRACE_LENGTH = X.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Model creation\n",
    "\n",
    "With model hyper-parameters to be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_mlp(x, y, x_attack, y_attack, params):\n",
    "    mdl = Sequential()\n",
    "    mdl.add(Dense(100, activation=params['activation'], input_shape=(x.shape[1],)))\n",
    "    mdl.add(Dense(100, activation=params['activation']))\n",
    "    mdl.add(Dense(100, activation=params['activation']))\n",
    "    mdl.add(Dense(100, activation=params['activation']))\n",
    "    mdl.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "    mdl.compile(optimizer=params['optimizer'], loss=params['losses'], metrics=['accuracy'])\n",
    "\n",
    "    out = mdl.fit(x, y, shuffle=True, validation_data=(x_attack, y_attack), batch_size=params['batch_size'],\n",
    "                  epochs=params['epochs'], verbose=False, callbacks=[TqdmCallback(verbose=0)])\n",
    "\n",
    "    return out, mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Brute-force Hyper parameter optimization\n",
    "\n",
    "Talos brute-force scan for optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import talos\n",
    "#\n",
    "# scan_obj = talos.Scan(x=x_prof,    y=y_prof,    x_val=x_att,    y_val=y_att,    model=make_mlp,    params=model_parameters,    experiment_name=\".cache/talos\", print_params=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fit model based on the optimal model found by Talos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_model = make_mlp(X, Y, X_ATT, Y_ATT, {\n",
    "    'activation':'relu',\n",
    "    'optimizer': Adam(learning_rate=0.001),\n",
    "    'losses': 'categorical_crossentropy',\n",
    "    'batch_size': 150,\n",
    "    'epochs': 5\n",
    "})[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### HW Prediction\n",
    "\n",
    "Predict the hamming weight by taking the weighted mean for the predicted probabilities for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Example: Some prediction\n",
    "\n",
    "Probabilities for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_model.predict(X_ATT[:1])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Predicted hamming weight label**, calculated by taking the weighted mean using the predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.sum(best_model.predict(X_ATT[:1])[0] * range(8 + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dlla_hw(best_model, X_ATT, Y_ATT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot prediction distribution for all traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# store_sns(plot_predictions(best_model, X_ATT, Y_ATT), \"dlla-9-predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot p-gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ATT, B_ATT = split_traces(X_ATT, Y_ATT, balance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LEN = round(len(A_ATT) / 2)\n",
    "TVLA_AB = Tvla(A_ATT.shape[1])\n",
    "TVLA_AB.add(A_ATT[:MAX_LEN], B_ATT)\n",
    "TVLA_BB = Tvla(TRACE_LENGTH)\n",
    "TVLA_BB.add(*random_divide(B_ATT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_p_gradient(dict([(f\"$\\\\mu_{{{d}}}$\", TVLA_AB.p_gradient(d)) for d in range(1, 4)]),\n",
    "                \"TVLA performance, first 3 statistical moment orders\\nMasked AES with 1400 sample points\", palette=PALETTE_GRADIENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "G = TVLA_AB.plot_p_values(2)\n",
    "store_sns(G, \"p-values-ascad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MAX_WEIGHTS = np.max(best_model.layers[0].get_weights()[0], axis=1)\n",
    "\n",
    "sns.lineplot(data=MAX_WEIGHTS)\n",
    "AX2 = plt.twinx()\n",
    "G = sns.lineplot(data=TVLA_AB.min_p[2], ax=AX2, color=sns.color_palette()[1], alpha=.5)\n",
    "G.set(yscale=\"log\")\n",
    "G.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"p-value for uncorrelated system producing these datasets\")\n",
    "pearsonr(MAX_WEIGHTS, TVLA_AB.min_p[2])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_p_gradient({\n",
    "    \"A vs. B\": TVLA_AB.p_gradient(2),\n",
    "    \"FP check\": TVLA_BB.p_gradient(2)\n",
    "}, \"TVLA min-$p$ performance validation ($t$-test for $\\\\mu_2$ with min-$p$)\\nMasked AES with 1400 sample points\",\n",
    "    palette=PALETTE_GRADIENT,\n",
    "    file_name=\"tvla-validation-mu2\")\n",
    "\n",
    "PG_LEN = len(TVLA_AB.p_gradient(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CRI_AB = cache_np(\"cri_tvla_pg_ab\", tvla_cri_p_gradient, TRACE_SET, 2, False, None, 1)\n",
    "CRI_RANDOM = cache_np(\"cri_tvla_pg_random\", tvla_cri_p_gradient, TRACE_SET, 2, True, None, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "NUM_TRACES = len(X)\n",
    "PG_CRI_AB = np.interp(range(NUM_TRACES), moving_average(CRI_AB[0], 5), moving_average(CRI_AB[1], 5))\n",
    "PG_CRI_RANDOM = np.interp(range(NUM_TRACES), moving_average(CRI_RANDOM[0], 5), moving_average(CRI_RANDOM[1], 5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PG_CRI_RANDOM = np.interp(range(NUM_TRACES), CRI_RANDOM[0], CRI_RANDOM[1])\n",
    "\n",
    "plot_p_gradient({\n",
    "    \"A vs. B\": PG_CRI_AB,\n",
    "    \"Random\": PG_CRI_RANDOM,\n",
    "}, \"TVLA performance validation ($t$-test for $\\\\mu_2$ with CRI min-$p$)\\nMasked AES with 1400 sample points\",\n",
    "    palette=PALETTE_GRADIENT,\n",
    "    file_name=\"tvla-cri-validation-mu2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PG_DLLA_9 = dlla_p_gradient(best_model, X_ATT, Y_ATT)[\"A vs. B\"]\n",
    "PG_DLLA_9_RANDOM = dlla_p_gradient(best_model, X_ATT, randomize(Y_ATT))[\"A vs. B\"]\n",
    "\n",
    "plot_p_gradient({\n",
    "    \"A vs. B\": np.array(PG_DLLA_9),\n",
    "    \"FP check\": np.array(PG_DLLA_9_RANDOM),\n",
    "}, \"DL-LA performance validation (9-class)\\nMasked AES with 1400 sample points\",\n",
    "    palette=PALETTE_GRADIENT,\n",
    "    file_name=\"dlla-9-validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_PROF_2, Y_PROF_2 = reduce_fixed_fixed(X, Y)\n",
    "X_ATT_2, Y_ATT_2 = reduce_fixed_fixed(X_ATT, Y_ATT)\n",
    "Y_ATT_2_RANDOM = randomize(Y_ATT_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_WEGENER_AB = make_mlp_wegener(X_PROF_2, Y_PROF_2)\n",
    "\n",
    "PG_DLLA_2_AB = wegener_p_gradient(MODEL_WEGENER_AB, X_ATT_2[:PG_LEN], Y_ATT_2[:PG_LEN])\n",
    "PG_DLLA_2_RANDOM =  wegener_p_gradient(MODEL_WEGENER_AB, X_ATT_2[:PG_LEN], Y_ATT_2_RANDOM[:PG_LEN])\n",
    "\n",
    "plot_p_gradient({\n",
    "    \"A vs. B\": np.array(PG_DLLA_2_AB),\n",
    "    \"FP check\": np.array(PG_DLLA_2_RANDOM),\n",
    "}, \"DL-LA performance validation (Wegener)\\nMasked AES with 1400 sample points\",\n",
    "    palette=PALETTE_GRADIENT,\n",
    "    file_name=\"dlla-2-validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_p_gradient({\n",
    "    \"DL-LA (9-class)\": np.array(PG_DLLA_9),\n",
    "    \"DL-LA (Wegener)\": np.array(PG_DLLA_2_AB),\n",
    "    \"TVLA $\\\\mu_2$ (min-$p$)\": TVLA_AB.p_gradient(2)\n",
    "},\"LA method performance\\nmasked AES with 1400 sample points\",\n",
    "    file_name=\"ascad-default-all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PGS = {\n",
    "    \"DL-LA 9-class\": np.repeat(np.array(PG_DLLA_9), 2)[:1000],\n",
    "    \"DL-LA Wegener\": np.array(PG_DLLA_2_AB[:1000]),\n",
    "}\n",
    "\n",
    "DF = pd.DataFrame(PGS)\n",
    "DF.to_csv(\"dlla-p-gradient.csv\")\n",
    "plot_p_gradient(PGS, \"LA method performance\\nmasked AES with 1400 sample points\",\n",
    "    file_name=\"ascad-default-dlla-1000\"\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}